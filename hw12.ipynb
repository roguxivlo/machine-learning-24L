{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT2j-dwiSTmC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roguxivlo/machine-learning-24L/blob/main/hw12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework Assignment: Is a *queen* really just a *king*, minus a *man*, plus a *woman*?**\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "\n",
        "In class, we dealt with **embeddings** trained for **sentiment classification**. These embeddings are optimized to separate *positive* from *negative* expressions and **do not encode deeper semantic information**.\n",
        "\n",
        "However, in modern natural language processing, there exist other embeddings — such as those from **BERT**, **word2vec**, or **GloVe** — that **do capture semantic structure**. These models are trained on large corpora, and their embeddings often allow for meaningful **vector arithmetic**, like the famous:\n",
        "\n",
        "```\n",
        "embedding(\"king\") - embedding(\"man\") + embedding(\"woman\") ≈ embedding(\"queen\")\n",
        "```\n",
        "\n",
        "This homework explores **semantic vector relationships** using such pretrained embeddings.\n",
        "\n",
        "## **The Objective**\n",
        "\n",
        "Your task is to:\n",
        "\n",
        "1. Construct semantic classes of word pairs.\n",
        "2. Visualize them using PCA.\n",
        "3. Explore arithmetic operations in embedding space.\n",
        "\n",
        "## **Tasks & Deliverables**\n",
        "\n",
        "### 1. **Semantic Pair Classes**\n",
        "\n",
        "- You must gather **at least 10 classes** of semantically related word pairs.\n",
        "- Each class must contain **at least 5 pairs**.\n",
        "- That gives a **minimum total of 100 unique words** (10 classes x 5 pairs x 2 words per pair).\n",
        "\n",
        "Two example classes:\n",
        "\n",
        "**Class 1: Gender**\n",
        "\n",
        "- (king, queen)\n",
        "- (man, woman)\n",
        "- (doctor, nurse)\n",
        "- (prince, princess)\n",
        "- *(you must add one more)*\n",
        "\n",
        "**Class 2: Verb tense (past tense)**\n",
        "\n",
        "- (bring, brought)\n",
        "- (get, got)\n",
        "- (like, liked)\n",
        "- *(you must add two more)*\n",
        "\n",
        "**Your job:**\n",
        "\n",
        "- Invent or search for **at least 10 such classes**, including the examples above.\n",
        "- Each class must be conceptually coherent.\n",
        "- Other examples: singular/plural, country/capital, comparative/superlative, tool/user, job/object, etc.\n",
        "\n",
        "### 2. **Global PCA (Across All Words)**\n",
        "\n",
        "- Use PCA to reduce the **entire set of 100 word embeddings** to 2D, and plot it.\n",
        "- Plot the additional **10 separate charts**, one for each class.\n",
        "  - Each chart should display only the 10 words (5 pairs) of the given class.\n",
        "- Points should be labeled with the words themselves.\n",
        "\n",
        "### 3. **Local PCA (Per Class)**\n",
        "\n",
        "- For each class (10 total), perform PCA **only** on the 10 words of that class.\n",
        "- Plot these class-wise PCA visualizations as separate charts.\n",
        "- Again, points should be labeled with the words.\n",
        "\n",
        "**Total: 21 charts**\n",
        "(1 global plot with 100 words + 10 global-space class plots + 10 local PCA class plots)\n",
        "\n",
        "Charts should be presented in a self-explanatory manner with clear labels.\n",
        "\n",
        "### 4. **Embedding Arithmetic**\n",
        "\n",
        "For each class, choose **one example pair** (e.g., (king, queen)) and perform the operation:\n",
        "\n",
        "```\n",
        "embedding(B) - embedding(A) + embedding(C)\n",
        "```\n",
        "\n",
        "Where A and B form a known pair, and C is another base word.\n",
        "For example:\n",
        "\n",
        "```\n",
        "embedding(\"king\") - embedding(\"man\") + embedding(\"woman\")\n",
        "```\n",
        "\n",
        "* For each such result vector, find the **5 closest word embeddings** (using cosine similarity or Euclidean distance).\n",
        "* Print the top 5 neighbors **with their distances**.\n",
        "* Do this **once per class** (i.e., 10 times).\n",
        "\n",
        "This will make it possible to verify if\n",
        " ```\n",
        "embedding(\"queen\") ≈ embedding(\"king\") - embedding(\"man\") + embedding(\"woman\")\n",
        "```\n",
        "for the *gender*-related class.\n",
        "\n",
        "\n",
        "### 5. **Discussion**\n",
        "\n",
        "* Analyze and interpret your 21 plots.\n",
        "* Discuss whether the vector relationships are preserved.\n",
        "* Does PCA capture semantic differences?\n",
        "* Are the closest words from the arithmetic meaningful?\n",
        "* What kinds of relationships are captured, and what are not?\n",
        "* Are some classes better behaved than others?\n",
        "\n",
        "\n",
        "### 6. **Publish on GitHub**  \n",
        "   - Place the Colab notebook in your **GitHub repository** for this course.\n",
        "   - In your repository’s **README**, add a **link** to the notebook and also include an **“Open in Colab”** badge at the top of the notebook so it can be launched directly from GitHub.\n",
        "\n",
        "\n",
        "## Acknowledgments\n",
        "\n",
        "*This homework assignment was inspired by an idea from my master's student **Andrzej Małek**, to whom I would like to express my thanks.*\n",
        "\n"
      ],
      "metadata": {
        "id": "7i7ZuhwzjdMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Semantic pair classes"
      ],
      "metadata": {
        "id": "cHY0UrOJlq4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "semantic_classes = {\n",
        "    \"Gender\": [\n",
        "        (\"king\", \"queen\"),\n",
        "        (\"man\", \"woman\"),\n",
        "        (\"doctor\", \"nurse\"),\n",
        "        (\"prince\", \"princess\"),\n",
        "        (\"actor\", \"actress\"),\n",
        "    ],\n",
        "    \"Verb Tense (Past)\": [\n",
        "        (\"bring\", \"brought\"),\n",
        "        (\"get\", \"got\"),\n",
        "        (\"like\", \"liked\"),\n",
        "        (\"go\", \"went\"),\n",
        "        (\"eat\", \"ate\"),\n",
        "    ],\n",
        "    \"Singular-Plural\": [\n",
        "        (\"cat\", \"cats\"),\n",
        "        (\"dog\", \"dogs\"),\n",
        "        (\"house\", \"houses\"),\n",
        "        (\"car\", \"cars\"),\n",
        "        (\"book\", \"books\"),\n",
        "    ],\n",
        "    \"Country-Capital\": [\n",
        "        (\"france\", \"paris\"),\n",
        "        (\"germany\", \"berlin\"),\n",
        "        (\"italy\", \"rome\"),\n",
        "        (\"japan\", \"tokyo\"),\n",
        "        (\"spain\", \"madrid\"),\n",
        "    ],\n",
        "    \"Comparative-Superlative\": [\n",
        "        (\"good\", \"best\"), # Irregular\n",
        "        (\"bad\", \"worst\"), # Irregular\n",
        "        (\"fast\", \"fastest\"),\n",
        "        (\"tall\", \"tallest\"),\n",
        "        (\"happy\", \"happiest\"),\n",
        "    ],\n",
        "    \"Tool-User/Profession\": [\n",
        "        (\"hammer\", \"carpenter\"),\n",
        "        (\"microphone\", \"singer\"),\n",
        "        (\"scalpel\", \"surgeon\"),\n",
        "        (\"microscope\", \"scientist\"),\n",
        "        (\"paint\", \"painter\"),\n",
        "    ],\n",
        "    \"Object-Property\": [\n",
        "        (\"lemon\", \"sour\"),\n",
        "        (\"sugar\", \"sweet\"),\n",
        "        (\"fire\", \"hot\"),\n",
        "        (\"ice\", \"cold\"),\n",
        "        (\"sun\", \"bright\"),\n",
        "    ],\n",
        "    \"Animal-Habitat\": [\n",
        "        (\"lion\", \"savanna\"),\n",
        "        (\"fish\", \"water\"),\n",
        "        (\"bird\", \"sky\"),\n",
        "        (\"bear\", \"forest\"),\n",
        "        (\"whale\", \"ocean\"),\n",
        "    ],\n",
        "    \"Part-Whole\": [\n",
        "        (\"toe\", \"foot\"),\n",
        "        (\"petal\", \"flower\"),\n",
        "        (\"leaf\", \"plant\"),\n",
        "        (\"engine\", \"plane\"),\n",
        "        (\"branch\", \"tree\"),\n",
        "    ],\n",
        "    \"Antonyms\": [\n",
        "        (\"love\", \"hate\"),\n",
        "        (\"big\", \"small\"),\n",
        "        (\"up\", \"down\"),\n",
        "        (\"open\", \"close\"),\n",
        "        (\"day\", \"night\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Verify no duplicates:\n",
        "\n",
        "words = set()\n",
        "\n",
        "for semantic_class, pairs in semantic_classes.items():\n",
        "    for (a,b) in pairs:\n",
        "        if a in words:\n",
        "            print(a)\n",
        "        if b in words:\n",
        "            print(b)\n",
        "        words.add(a)\n",
        "        words.add(b)\n",
        "\n",
        "print(f\"Total: {len(words)} words\")\n"
      ],
      "metadata": {
        "id": "DOI_IpTdkHJN",
        "outputId": "e522d1d2-5e8d-4c98-bad1-9589d445363f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 100 words\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}